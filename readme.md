
## **ğŸ“ README.md (Atriva AI API)**

```md
# Atriva AI API with OpenVINO ğŸš€

This is a FastAPI-based AI API that leverages **OpenVINO** for optimized deep learning inference.  
It provides a RESTful interface for running AI models, such as object detection and image classification.

## **ğŸ“‚ Project Structure**
```plaintext
atriva-ai-openvino/
â”‚â”€â”€ app/
â”‚   â”œâ”€â”€ routes.py         # API route definitions
â”‚   â”œâ”€â”€ services.py       # AI model processing logic
â”‚   â”œâ”€â”€ models.py         # Data models and schemas
â”‚   â”œâ”€â”€ model_capabilities.py  # Model capabilities and metadata
â”‚   â”œâ”€â”€ shared_data.py    # Shared data utilities
â”‚â”€â”€ models/               # Pretrained OpenVINO models
â”‚   â”œâ”€â”€ yolov8n/          # YOLOv8n object detection model
â”‚   â”œâ”€â”€ lprnet/           # LPRNet license plate recognition model
â”‚   â””â”€â”€ vehicle_tracking/ # Vehicle detection and tracking model
â”‚â”€â”€ tests/                # Comprehensive testing suite
â”‚   â”œâ”€â”€ test_runner.py    # Main test runner
â”‚   â”œâ”€â”€ test_yolov8n.py   # YOLOv8n specific tests
â”‚   â”œâ”€â”€ test_lprnet.py    # LPRNet specific tests
â”‚   â”œâ”€â”€ test_vehicle_tracking.py  # Vehicle tracking tests
â”‚   â””â”€â”€ setup.sh          # Test environment setup
â”‚â”€â”€ main.py               # Entry point for FastAPI
â”‚â”€â”€ config.py             # Configuration settings
â”‚â”€â”€ requirements.txt      # Python dependencies
â”‚â”€â”€ Dockerfile            # Docker configuration
â”‚â”€â”€ README.md             # Project documentation
```

## **âš¡ Features**
âœ… FastAPI-based AI API  
âœ… OpenVINO optimization for inference  
âœ… Dockerized for easy deployment  
âœ… Comprehensive testing suite  
âœ… Multiple AI models supported:
   - YOLOv8n Object Detection
   - LPRNet License Plate Recognition
   - Vehicle Detection and Tracking  

## **ğŸ”§ Setup & Installation**

### **1ï¸âƒ£ Clone the Repository**
```sh
git clone https://github.com/atriva-ai/atriva-ai-openvino.git
cd atriva-ai-openvino
```

### **2ï¸âƒ£ Create a Virtual Environment**
```sh
python3 -m venv venv
source venv/bin/activate  # On Windows, use `venv\Scripts\activate`
pip install -r requirements.txt
```

### **3ï¸âƒ£ Run the API Locally**
```sh
uvicorn main:app --host 0.0.0.0 --port 8000 --reload
```
Access the API documentation at:  
ğŸ‘‰ **http://localhost:8000/docs**

## **ğŸ³ Running with Docker**
### **1ï¸âƒ£ Build the Docker Image**
```sh
docker build -t atriva-ai-openvino .
```

### **2ï¸âƒ£ Run the Container**
```sh
docker run -d -p 8000:8000 --name ai-openvino-container atriva-ai-openvino
```
Now, visit:  
ğŸ‘‰ **http://localhost:8000/docs**

## **ğŸ›  API Endpoints**
| Method | Endpoint         | Description          |
|--------|-----------------|----------------------|
| `GET`  | `/`             | Health check        |
| `POST` | `/predict`      | Run AI inference    |

## **ğŸ§ª Running Tests**
```sh
# Setup test environment
cd tests
./setup.sh
source venv/bin/activate

# Download models
python test_runner.py --download-models

# Run all tests
python test_runner.py --model all --input test_images/sample.jpg

# Test specific model
python test_yolov8n.py --input test_images/sample_cars.jpg
```

## **ğŸ¤– Available Models**

### **YOLOv8n Object Detection**
- **Purpose**: Detect 80 different object classes
- **Input**: 640Ã—640 RGB images
- **Output**: Bounding boxes with class labels and confidence scores
- **Use Cases**: General object detection, surveillance, autonomous vehicles

### **LPRNet License Plate Recognition**
- **Purpose**: Recognize license plate text
- **Input**: 24Ã—94 RGB images (license plate regions)
- **Output**: Recognized text with character-level confidence
- **Use Cases**: Parking management, traffic enforcement, access control

### **Vehicle Detection and Tracking**
- **Purpose**: Detect and track vehicles across video frames
- **Input**: 416Ã—416 RGB images
- **Output**: Vehicle bounding boxes with unique track IDs
- **Use Cases**: Traffic monitoring, parking analytics, fleet management

## **ğŸ“œ License**
This project is licensed under the **MIT License**.

